---
title: "Instrumental Variables Simulation"
questions author: "Jenn1fer H1ll, Ray Lu & Zarn1 Htet" #obfuscated
answers: "Margar1ta B0yarskaya" #obfuscated
output: pdf_document
---
```{r, echo=FALSE, message=FALSE}
library(dplyr)
library(AER)


#comment from Dec 11 2020: I am realizing my code for generating potentil outcomes is dead wrong. I should have gotten unbiased estimates if all assumptions are satisfied. See the exam submission (Q2) for the correct way of generation potential outcomes.
```
@@ Objective 

The goal of this exercise is to simulate data consistent with the assumptions of the IV estimaator we discussed in class (and described in the Angrist, Imbens, Rubin article posted on the Classes site).  We will also evaluate the properties of different approaches to estimating the Complier Average Causal Effect. 

@@ Setting

To help conceptualize data that might be consistent with the IV assumptions, we will generate data from a hypothetical randomized encouragment design.  In particular, imagine a study in which 1000 students entering an undergraduate degree program in the sciences in a major university were randomly assigned to one of two conditions.  One group was encouraged via an email from the chair of their department to participate in a one week math boot camp just before the start of their first semester.  Students in the other (not encouraged) group were also allowed to participate but received no special encouragement.  In fact they would have had to discover on their own the existence of the program on the university website.  The outcome variable is derived from the student test scores on the final exam for required math course for the sciences.  In particular the Y variable that you will simulate below represents the *difference* between that score and the threshold for passing.  Thus a negative value for a student reflects that the student did not pass.

@@ Question 1. Simulate the data as god/goddess/supreme being of your choice.
In this section you will simulate data consistent with the assumptions.
You will generate data for a sample of 1000 individuals.

(a) Simulate compliance status.
Assume that 25% of individuals are compliers, 60% are never takers, and 15% are always takers.  Generate D(0) and D(1) vectors to reflect this.  You can also generate a vector indicating compliance type, C, if that is helpful to you.
```{r}
set.seed(1234)

# Treatment (tutoring) assignment:
pop_sz = 1000

#compliance types:
C <- c(rep('C', 0.25*pop_sz), rep('NT', 0.6*pop_sz), rep('AT', 0.15*pop_sz))
C <- sample(C) # maybe this is not necessary

#assignment into encouragement groups:
Z  <- rbinom(pop_sz, 1, 0.5) 

dat.full <- data.frame(C, Z) 

# Would have taken the tutoring program, had they received the encouragement? Aka D(Z=1):
dat.full['D_Z1'] <- (dat.full$C=="C")*1 + (dat.full$C=="AT")*1
# Would have taken the tutoring program, had they NOT received the encouragement? Aka D(Z=0):
dat.full['D_Z0'] <- (dat.full$C=="C")*0 + (dat.full$C=="AT")*1

head(dat.full)
```

(b) Which compliance group has been omitted from consideration?  What assumption does that imply?   
   
@@@@@@@@@@@@@@@@@ ANSWER @@@@@@@@@@@@@@@@@@@@@@@   
Defyers have been omitted. This implies adherence to the monotonicity assumption.   
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@   

(c) Simulate the potential outcomes in a way that meets the following criteria:
  (i) The exclusion restriction is satisfied.
  (ii) The average effect of Z on Y for the compliers is 4.
  (iii) The average Y(Z=0) for never takers is 0; The average Y(0) for compliers is 3; The average Y(Z=0) for always takers is 6.
  (iii) The residual standard deviation is 1 for everyone in the sample (generated independently for each potential outcome).

```{r}
avg_y0_nt <- 0
avg_y0_c <- 3
avg_y0_at <- 6

avg_y1_c <- avg_y0_c + 4

dat.full['Y_0'] <- avg_y0_nt*(dat.full$C=='NT') + avg_y0_at*(dat.full$C=='AT') + 
  avg_y0_c*(dat.full$C=='C') + rnorm(pop_sz, mean = 0, sd = 1)
dat.full['Y_1'] <- avg_y1_c*(dat.full$C=='C') + rnorm(pop_sz, mean = 0, sd = 1)

head(dat.full)

#check that the criteria are satisfied:
ET_i <- dat.full['Y_1']-dat.full['Y_0']
SATE_compliers <- mean(ET_i[dat.full$C=='C',1])
print("SATE on compliers:")
print(SATE_compliers)

print("Average Y_0 for different compliance groups:")
mean(dat.full$Y_0[dat.full$C=='NT'])
mean(dat.full$Y_0[dat.full$C=='C'])
mean(dat.full$Y_0[dat.full$C=='AT'])
#OK
```

(d) Calculate the SATE (average effect of Z on Y) for each of the compliance groups.
```{r}
print("SATE for compliers:")
print(SATE_compliers)

print("SATE for always takers:")
print(mean(ET_i[dat.full$C=='AT',1]))
      
print("SATE for never takers:")
print(mean(ET_i[dat.full$C=='NT',1]))

# looks OK. the effect for the always takers takes this value because mean of Y_0 
# was specified in the task, while mean(Y_1) was not. 
# I left the mean of Y_1 for this group to be zero when generating data.
```
(e) What is another name for the SATE for the compliers?    

@@@@@@@@@@@@# ANSWER: @@@@@@@@@   
Complier Average Causal Effect   
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@   

(f) Calculate the ITT using your simulated data.
```{r}
ITT <- mean(ET_i[, 1])
ITT
```

(g) Put D(0), D(1), Y(0), Y(1) into one dataset called dat.full.
(You can also include a variable, C, indicating compliance group if you
created one.)

@@@#
already done above
@@@

@@ Question 2. Playing the role of the researcher to randomly assign treatments to observations.
Now switch to the role of the researcher. Pretend that you are running the experiment that we are examining for this assignment.  Generate a binary indicator for the ignorable treatment *assignment* (as distinct from treatment receipt.... so this is $Z$, not $D$).  Probability of receiving the treatment should be .5.

@@@
also done
@@@

@@ Question 3. Back to playing god to understand which potential outcome manifests as an observed outcome.
Use dat.full to create a dataset that the researcher would actually get to see given the Z generated in Question 2.  It should only have D, Z, and Y in it.  Call it dat.obs.
```{r}
dat.obs <- data.frame(Z=dat.full$Z)
dat.obs['D'] <- dat.full$D_Z0*(1-dat.full$Z) + dat.full$D_Z1*dat.full$Z
dat.obs['Y'] <- dat.full['Y_0']*(1-dat.full['Z']) + dat.full['Y_1']*dat.full['Z']
head(dat.obs)
```
@@ Question 4. Estimate some quantities of interest as a researcher.
(a) *Estimate* the percent of compliers, never takers and always takers assuming that there are no defiers.  Use only information in dat.obs.
```{r}
#Assumption: treatment assignment Z is random.
#This means the proportion of each compliance type is the same whether Z = 0 or Z = 1.
# E[d | z=1] - E[d | z=0]
n_Z0D1 <- count(dat.obs[(dat.obs$Z==0)&(dat.obs$D==1),])
n_Z1D1 <- count(dat.obs[(dat.obs$Z==1)&(dat.obs$D==1),])

prop_AT <- n_Z0D1/nrow(dat.obs[dat.obs$Z==0,])
prop_C <- n_Z1D1/nrow(dat.obs[dat.obs$Z==1,]) - prop_AT
prop_NT <- 1 - prop_C - prop_AT

print(sprintf("proportion of compliers: %.4f", prop_C))
print(sprintf("proportion of always takers: %.4f", prop_AT))
print(sprintf("proportion of never takers: %.4f", prop_NT))

#or, equivalently:
# reg_D_on_Z <- lm(D~Z, data=dat.obs)
# prop_C <- coef(reg_D_on_Z)[2]
# prop_C
```

(b) Estimate the naive regression estimate of the effect of the treatment on the outcome.  Which estimand that we discussed in class is this equivalent to? 
```{r}
naive <- lm(Y~D, data = dat.obs)
summary(naive)
```
@@@@@@@@@@@@# ANSWER: @@@@@@@@@@@@@@@   
The estimated effect value is 4.36. This estimand is equivalent to the "as-treated" estimand, which compares thos ewho received the treatment with those who did not (where the latter group includes observations with various instrument assignment values).   
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@   

(c) Estimate the intention-to-treat effect.
```{r}
ITT <- summary(lm(Y~Z, data = dat.obs))$coefficients[2,1]
ITT
```

(d) Estimate the CACE by dividing the ITT estimate by the percent of compliers in the sample.
```{r}
CACE <- ITT/prop_C
colnames(CACE) <- c("CACE")
CACE
```
(e) Estimate the CACE by performing two stage least squares on your own (that is without using an IV function in the R package AER).  
```{r}
first_stage <- lm(D~Z, data = dat.obs)
D_hat <- predict(first_stage)
second_stage <- lm(dat.obs$Y~D_hat)
summary(second_stage)$coefficients[2,1]
```

(f) Provide an estimate of CACE and its standard error using the ivreg command in the AER package.
```{r}
ivreg_fit <- ivreg(Y ~ D|Z, data = dat.obs)
summary(ivreg_fit)$coefficients[2,1:2]
```
@@ Question 5. Back to god mode: sampling distribution

Simulate a sampling distribution (with 10000 draws) for the estimator used in (4f).  This will be simplified if you create a function from your simulation steps in Questions 1, 2, and 3. Is the estimator unbiased?  Also report the standard deviation of the sampling distribution and compare to the standard error from your original dataset in (4f). 

@@@@@@@@@   
first, let's pack our data generation into a function. Previously, I generated Z right away. Now I will remove that part fromt he code and instead generate treatment assignment for each sample.   
@@@@@@@@@   
```{r}
sim_data <- function(pop_sz){
  C <- c(rep('C', 0.25*pop_sz), rep('NT', 0.6*pop_sz), rep('AT', 0.15*pop_sz))
  C <- sample(C) # maybe this is not necessary

  dat.full <- data.frame(C) 

  dat.full['D_Z1'] <- (dat.full$C=="C")*1 + (dat.full$C=="AT")*1
  dat.full['D_Z0'] <- (dat.full$C=="C")*0 + (dat.full$C=="AT")*1
  
  avg_y0_nt <- 0
  avg_y0_c <- 3
  avg_y0_at <- 6

  avg_y1_c <- avg_y0_c + 4

  dat.full['Y_0'] <- avg_y0_nt*(dat.full$C=='NT') + avg_y0_at*(dat.full$C=='AT') + 
    avg_y0_c*(dat.full$C=='C') + rnorm(pop_sz, mean = 0, sd = 1)
  dat.full['Y_1'] <- avg_y1_c*(dat.full$C=='C') + rnorm(pop_sz, mean = 0, sd = 1)

  return(dat.full)
}

```

@@@@@@@@@# ANSWER: @@@@@@@@   
Now let's simulate a population. I will arbitrarily decide on the size of it.   
@@@@@@@@@@@@@@@@@@@@@@@@@@@   
```{r}
pop <- sim_data(13000)

CACE_ivreg_sampling<- c()

for(i in 1:10000){# 10000 draws
  
  sample <- sample_n(pop, 1000, replace = TRUE)
  #assignment into encouragement groups:
  sample_Z <- rbinom(1000, 1, 0.5)
  sample.obs <- data.frame(Z=sample_Z)
  sample.obs['D'] <- sample$D_Z0*(1-sample_Z) + sample$D_Z1*sample_Z
  sample.obs['Y'] <- sample['Y_0']*(1-sample_Z) + sample['Y_1']*sample_Z

  # CACE via ivreg, as in 4(f):
  this_ivreg_fit <- ivreg(Y ~ D|Z, data = sample.obs)
  this_CACE <- summary(this_ivreg_fit)$coefficients[2,1]
  CACE_ivreg_sampling <- c(CACE_ivreg_sampling, this_CACE)
}

```

```{r}
#head(CACE_ivreg_sampling)
print(sprintf("Mean of sampling distirbution CACE: %.3f", mean(CACE_ivreg_sampling)))
print(sprintf("SD of the sampling distirbution CACE: %.3f", sd(CACE_ivreg_sampling)))
```
@@@@@@@@@@@@@@ ANSWER @@@@@@@@@@@@@@      
The mean of the CACE computed for all samples is 0.418, which is close to the DGP value of 4.   
The estimator has very small bias.  
The standard deviation of the sampling distirbution CACE is 0.702, which is close to but slightly larger than   
the 0.69 value we obtained ont he original distirbution in 4(f).  
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@    

@@ Question 6. Back to god mode: sampling distribution, assumptions
(a) Describe the assumptions required to obtain and unbiased estimate of the treatment effect, as described in AIR.  We have generated data that satisfy these assumptions.  Suppose instead you were handed data from the study described above.  Comment on the plausibility of each of the required assumptions in that setting.

@@@@@@@@@@@@@@@ ANSWER: @@@@@@@@@@@@@@@@@   
1) Random assignment of Z. In our context, this would mean that the student body is randomly assigned into encouragement (receiving an e-mail from the chair) and no ecnouragement groups.  
- A weak, plausible assumption.

2) Exclusion restriction (Z affects Y only via D). This would mean that receiving the email from the chair does not directly   influence the outcome of the test. In particular, the groups whose compliance is insensitive to the instrumental encourgament   (never takers, always takers) should get the same results given that they *did* receive an email as they would have obtained *had   they not* recieved the email.   
- This is a reasonable assumption. Receiving the encouragement should not in intself influence the test outcome other than by way of the bootcamp (unless test results are attached to the end of the chair's email). Although in reality, one can never be too cautious when asserting absence of paths between variables.

3) Monotonicity (no defiers). This means that we deny the possibility of the folliwing student profile: students who partake in boot camp if they *do not* recevive the email, and avoid the boot camp if they are invited to partake.
- Perhaps this is not a very controversial assumption. It is likely to hold. If it doesn't hold, perhaps we can expect there to be very few defiers, but our estimates as computed above would suffer from bias.

4) Non-zero correlation between instrument and treatment. We assume the impossibility of a situation where emails do not affect anyone's decision to take or not take the boot camp.
- I think it is a plausible assumption, although in reality the effect is small, and I would expect an instrument like this to be weak. 

5) SUTVA. No influence between individual student decisions to take or not take the boot camp. 
- This is a strong assumption. First of all, simply being informed about the fact that one student plans to attend the bootcamp amounts for some students to *finding out about the bootcamp*, and for some of those students this will be enough of an encouragement to *take the bootcamp*. Moreover, some students like organizing together when going to tutoring/TA/bootcamps/office hours and thus receive a *social* incentive to attend the bootcamp, where a simple e-mail from the chair on ots own perhaps would not have been enough of an encouragement.   
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@   

(b) Suppose that the data generating process above included a covariate that predicted both Z and Y.  Which of the assumptions described in (a) would that change and how?
   
@@@@@@@@@@@@@@@ ANSWER: @@@@@@@@@@@@@@@@@   
For example, if the students have differential access to e-mails, influenced by their Socio-Economic status, and the latter also influences test results via, say, time left for preparing for tests after other (family, job) responsibilities are taken care of.
This would violate the ignorability assumption.
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@   
   
(c) Suppose that the directions for Q1.c.iii was amended as follows
"  (iii) The average Y(0) for never takers is 0; The average Y(0) for compliers is 3; The average Y(0) for always takers is 6.  The average Y(1) for never takers is 2."
Which of the assumptions described in (a) would that violate?
   
@@@@@@@@@@@@@@@ ANSWER: @@@@@@@@@@@@@@@@@   
This would violate the monotonicity assumption.   
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@   

(d) Redo one of the commands from Question 1 (just provide the code -- you don't have to run it) such that the monotonicy assumption is violated.

```{r}
sim_data <- function(pop_sz){
  
  C <- c(rep('C', 0.25*pop_sz), rep('NT', 0.6*pop_sz), rep('AT', 0.15*pop_sz))
  C <- sample(C) # maybe this is not necessary

  Z  <- rbinom(pop_sz, 1, 0.5) 
  
  dat.full <- data.frame(C, Z) 

  dat.full['D_Z1'] <- (dat.full$C=="C")*1 + (dat.full$C=="AT")*1
  dat.full['D_Z0'] <- (dat.full$C=="C")*0 + (dat.full$C=="AT")*1
  
  avg_y0_nt <- 0
  avg_y0_c <- 3
  avg_y0_at <- 6

  avg_y1_nt <- 2

  dat.full['Y_0'] <- avg_y0_nt*(dat.full$C=='NT') + avg_y0_at*(dat.full$C=='AT') + 
    avg_y0_c*(dat.full$C=='C') + rnorm(pop_sz, mean = 0, sd = 1)
  dat.full['Y_1'] <- avg_y1_nt*(dat.full$C=='NT') + rnorm(pop_sz, mean = 0, sd = 1)

  return(dat.full)
}

```

```{r}
data_nonmon <- sim_data(1000)

ET_i <- data_nonmon['Y_1']-data_nonmon['Y_0']
SATE_compliers <- mean(ET_i[data_nonmon$C=='C',1])
print("SATE on compliers:")
print(SATE_compliers)

print("Average Y_0 for different compliance groups:")
mean(data_nonmon$Y_0[data_nonmon$C=='NT'])
mean(data_nonmon$Y_0[data_nonmon$C=='C'])
mean(data_nonmon$Y_0[data_nonmon$C=='AT'])

print("SATE for compliers:")
print(SATE_compliers)

print("SATE for always takers:")
print(mean(ET_i[data_nonmon$C=='AT',1]))
      
print("SATE for never takers:")
print(mean(ET_i[data_nonmon$C=='NT',1]))

ITT <- mean(ET_i[, 1])
ITT
```
(e) How could we alter the study design to preclude the existence of always takers?  Would this be ethical?
  
@@@@@@@@@@@@@@@ ANSWER: @@@@@@@@@@@@@@@@@  
One could try to make them self-identify and then simply exclude them from the 'population' when assigning Z. 
In order to identify always-takers, some kind of survey study could be conducted, where students are asked to mark their interest and intention to attend a hypothetical study bootcamp. 
Another idea is to prohibit the students from taking the bootcamp if they took 5 bootcamps in the past. This is a crude proxy for always-takers, which is very frail and relies on assuming that these people are not defyers AND that propensity to comply in the past is transferable onto the upcoming experiment, AND that past treatment (all those past math bootcamps) do not influence the outcome of this one. So, in short, a very bad idea :) 
Perhaps making students self-identify as always-takers via a survey/poll is a better way to go.
  
Excluding the always-takers is not an ethical practice, because that bootcamp may indeed have a positive effect on the test result.   
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@  